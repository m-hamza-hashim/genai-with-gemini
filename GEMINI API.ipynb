{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3kVk1Mycn6MF"
   },
   "source": [
    "#GEMINI NORMAL PROMPTING API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "executionInfo": {
     "elapsed": 4176,
     "status": "ok",
     "timestamp": 1737341808045,
     "user": {
      "displayName": "Hamza Hashim",
      "userId": "13752771049705334670"
     },
     "user_tz": -300
    },
    "id": "NlpILPiVnLec",
    "outputId": "81be7385-b5d1-4b98-a10d-404bc2b31f17"
   },
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "from google.colab import userdata\n",
    "\n",
    "genai.configure(api_key=userdata.get('GOOGLE_API_KEY'))\n",
    "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "response = model.generate_content(\"Hello, how are you?!\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1737341808045,
     "user": {
      "displayName": "Hamza Hashim",
      "userId": "13752771049705334670"
     },
     "user_tz": -300
    },
    "id": "JgbFtil0gLNf",
    "outputId": "b1969442-8c8b-4194-f1ed-d8cbbcd41344"
   },
   "outputs": [],
   "source": [
    "!curl -o image.jpg \"https://storage.googleapis.com/generativeai-downloads/images/jetpack.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "executionInfo": {
     "elapsed": 5952,
     "status": "ok",
     "timestamp": 1737341813992,
     "user": {
      "displayName": "Hamza Hashim",
      "userId": "13752771049705334670"
     },
     "user_tz": -300
    },
    "id": "9oukpnRStK1a",
    "outputId": "2ed75c2c-f54a-4762-f3ce-eec5a676bdff"
   },
   "outputs": [],
   "source": [
    "import PIL.Image\n",
    "\n",
    "organ = PIL.Image.open(\"image.jpg\")\n",
    "response = model.generate_content([\"describe this\", organ])\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "executionInfo": {
     "elapsed": 3180,
     "status": "ok",
     "timestamp": 1737341817157,
     "user": {
      "displayName": "Hamza Hashim",
      "userId": "13752771049705334670"
     },
     "user_tz": -300
    },
    "id": "51LmBgi5ukMM",
    "outputId": "b7c2c483-0608-4550-fedf-9369f33a90c6"
   },
   "outputs": [],
   "source": [
    "chat = model.start_chat(\n",
    "    history=[\n",
    "        {\"role\": \"user\", \"parts\": \"Hello\"},\n",
    "        {\"role\": \"model\", \"parts\": \"Great to meet you. What would you like to know?\"},\n",
    "    ]\n",
    ")\n",
    "\n",
    "response = chat.send_message(\"I have 2 dogs in my house.\")\n",
    "print(response.text)\n",
    "response2 = chat.send_message(\"give me a summary of my entire conversation with you uptil now\")\n",
    "print(response2.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "executionInfo": {
     "elapsed": 3064,
     "status": "ok",
     "timestamp": 1737341820208,
     "user": {
      "displayName": "Hamza Hashim",
      "userId": "13752771049705334670"
     },
     "user_tz": -300
    },
    "id": "gVvY1fyku95K",
    "outputId": "b54b0237-670c-420a-c55a-eb9698de5c33"
   },
   "outputs": [],
   "source": [
    "chat.send_message(\"my name is hamza\")\n",
    "response = chat.send_message(\"now give me a summary of our conversation\", generation_config = genai.GenerationConfig(\n",
    "        max_output_tokens=50,\n",
    "        temperature=0.1,))\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1737341820209,
     "user": {
      "displayName": "Hamza Hashim",
      "userId": "13752771049705334670"
     },
     "user_tz": -300
    },
    "id": "3G4-Uj7bvqWS",
    "outputId": "3de7a6ed-3a1f-49c2-85a5-f20e2324dcff"
   },
   "outputs": [],
   "source": [
    "print(chat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9TpDfsInv_6w"
   },
   "source": [
    "#GEMINI LIVE API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13751,
     "status": "ok",
     "timestamp": 1737341833951,
     "user": {
      "displayName": "Hamza Hashim",
      "userId": "13752771049705334670"
     },
     "user_tz": -300
    },
    "id": "gLyYx9ZzwKyi",
    "outputId": "1170ed28-f062-4da1-9038-a93ecac59ba9"
   },
   "outputs": [],
   "source": [
    "!pip install -U -q google-genai\n",
    "\n",
    "\n",
    "from google.colab import userdata\n",
    "from google import genai\n",
    "from google import genai\n",
    "import os\n",
    "\n",
    "os.environ['GOOGLE_API_KEY'] = userdata.get('GOOGLE_API_KEY')\n",
    "\n",
    "client = genai.Client()\n",
    "\n",
    "MODEL: str = \"gemini-2.0-flash-exp\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=MODEL, contents='How does AI work?'\n",
    ")\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NcpK69p_vn4s"
   },
   "source": [
    "# GEMINI FUNCTION CALLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m4DhA4907Asz"
   },
   "outputs": [],
   "source": [
    "!pip install -U -q \"google-generativeai>=0.7.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wp3W4Pdf8rBO"
   },
   "outputs": [],
   "source": [
    "from google.colab import userdata\n",
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=userdata.get(\"GOOGLE_API_KEY_1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gLS26n7A9l9B"
   },
   "outputs": [],
   "source": [
    "def enable_lights():\n",
    "    \"\"\"Turn on the lighting system.\"\"\"\n",
    "    print(\"LIGHTBOT: Lights enabled.\")\n",
    "\n",
    "\n",
    "def set_light_color(rgb_hex: str):\n",
    "    \"\"\"Set the light color. Lights must be enabled for this to work.\"\"\"\n",
    "    print(f\"LIGHTBOT: Lights set to {rgb_hex}.\")\n",
    "\n",
    "\n",
    "def stop_lights():\n",
    "    \"\"\"Stop flashing lights.\"\"\"\n",
    "    print(\"LIGHTBOT: Lights turned off.\")\n",
    "\n",
    "\n",
    "light_controls = [enable_lights, set_light_color, stop_lights]\n",
    "instruction = \"You are a helpful lighting system bot. You can turn lights on and off, and you can set the color. Do not perform any other tasks.\"\n",
    "\n",
    "model = genai.GenerativeModel(\n",
    "    \"models/gemini-1.5-pro\", tools=light_controls, system_instruction=instruction\n",
    ")\n",
    "\n",
    "chat = model.start_chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_QgLFPL4Chon"
   },
   "outputs": [],
   "source": [
    "from google.generativeai.types import content_types\n",
    "from collections.abc import Iterable\n",
    "\n",
    "\n",
    "def tool_config_from_mode(mode: str, fns: Iterable[str] = ()):\n",
    "    \"\"\"Create a tool config with the specified function calling mode.\"\"\"\n",
    "    return content_types.to_tool_config(\n",
    "        {\"function_calling_config\": {\"mode\": mode, \"allowed_function_names\": fns}}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "executionInfo": {
     "elapsed": 3598,
     "status": "ok",
     "timestamp": 1737738954270,
     "user": {
      "displayName": "Hamza Hashim",
      "userId": "13752771049705334670"
     },
     "user_tz": -300
    },
    "id": "6ZlIFwXqGA09",
    "outputId": "67d5dbad-7f64-4634-b341-30f5d8a7c61c"
   },
   "outputs": [],
   "source": [
    "# make sure when automatic function calling switched off then mention the command in detail including every step like first open the light, then make it purple and then switch off the light etc as sometimes problem is occuring that when direct command is given second function is being run directly. no such problem when automatic function calling enabled\n",
    "\n",
    "tool_config = tool_config_from_mode(\"none\")\n",
    "\n",
    "response = chat.send_message(\n",
    "    \"Hello light-bot, what can you do?\", tool_config=tool_config\n",
    ")\n",
    "print(response.parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "executionInfo": {
     "elapsed": 2385,
     "status": "ok",
     "timestamp": 1737738986589,
     "user": {
      "displayName": "Hamza Hashim",
      "userId": "13752771049705334670"
     },
     "user_tz": -300
    },
    "id": "vwO9dUjvHoT8",
    "outputId": "ab7ce8b0-51c9-4044-c04f-b39afb1b6abe"
   },
   "outputs": [],
   "source": [
    "tool_config = tool_config_from_mode(\"auto\")\n",
    "\n",
    "response = chat.send_message(\"Light this place up!\", tool_config=tool_config)\n",
    "print(response.parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "executionInfo": {
     "elapsed": 3472,
     "status": "ok",
     "timestamp": 1737739010037,
     "user": {
      "displayName": "Hamza Hashim",
      "userId": "13752771049705334670"
     },
     "user_tz": -300
    },
    "id": "GQpz94zrCNJF",
    "outputId": "50f30a39-b5a9-469a-d42e-2c709fd977d3"
   },
   "outputs": [],
   "source": [
    "available_fns = [\"set_light_color\", \"stop_lights\"]\n",
    "\n",
    "tool_config = tool_config_from_mode(\"any\", available_fns)\n",
    "\n",
    "response = chat.send_message(\"Make this place PURPLE!\", tool_config=tool_config)\n",
    "print(response.parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "executionInfo": {
     "elapsed": 6122,
     "status": "ok",
     "timestamp": 1737741773065,
     "user": {
      "displayName": "Hamza Hashim",
      "userId": "13752771049705334670"
     },
     "user_tz": -300
    },
    "id": "hx7aIX8OXvi6",
    "outputId": "041bae38-1b09-43bb-c2df-44b2285e48bf"
   },
   "outputs": [],
   "source": [
    "tool_config = tool_config_from_mode(\"auto\")\n",
    "\n",
    "auto_chat = model.start_chat(enable_automatic_function_calling=True)\n",
    "response = auto_chat.send_message(\"make this place purple\", tool_config=tool_config)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cUAtg-FXIEZG"
   },
   "source": [
    "# Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cbcf72bcb56d"
   },
   "outputs": [],
   "source": [
    "!pip install -q google-generativeai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jdIYSl2kN0cq"
   },
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8enrppafJPCX"
   },
   "outputs": [],
   "source": [
    "import google.generativeai as genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lhqVUjH7ZKUi"
   },
   "outputs": [],
   "source": [
    "from google.colab import userdata\n",
    "genai.configure(api_key=userdata.get('GOOGLE_API_KEY'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P-MYZECwlRCq"
   },
   "source": [
    "You can check you existing tuned models with the `genai.list_tuned_model` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "executionInfo": {
     "elapsed": 4817,
     "status": "ok",
     "timestamp": 1737895670878,
     "user": {
      "displayName": "Hamza Hashim",
      "userId": "13752771049705334670"
     },
     "user_tz": -300
    },
    "id": "XyWzoYFxU4r6",
    "outputId": "228c2b6e-afc6-4909-f065-54147944975e"
   },
   "outputs": [],
   "source": [
    "for i, m in zip(range(5), genai.list_tuned_models()):\n",
    "  print(m.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BhkXRzciv3Dp"
   },
   "source": [
    "## Create tuned model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OO8VZYAinLWc"
   },
   "source": [
    "To create a tuned model, you need to pass your dataset to the model in the `genai.create_tuned_model` method. You can do this be directly defining the input and output values in the call or importing from a file into a dataframe to pass to the method.\n",
    "\n",
    "For this example, you will tune a model to generate the next number in the sequence. For example, if the input is `1`, the model should output `2`. If the input is `one hundred`, the output should be `one hundred one`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 243
    },
    "executionInfo": {
     "elapsed": 2829,
     "status": "ok",
     "timestamp": 1737895676262,
     "user": {
      "displayName": "Hamza Hashim",
      "userId": "13752771049705334670"
     },
     "user_tz": -300
    },
    "id": "w-EBSe9wTbLB",
    "outputId": "1b4c4903-3d3c-40b4-e3fe-00eba86c39ae"
   },
   "outputs": [],
   "source": [
    "base_model = [\n",
    "    m for m in genai.list_models()\n",
    "    if \"createTunedModel\" in m.supported_generation_methods and\n",
    "    \"flash\" in m.name][0]\n",
    "base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sh8nB7J7GLqP"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load training data from the file\n",
    "with open('training_data.json', 'r') as file:\n",
    "    training_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "baHjHh1oTTTC"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "name = f'generate-num-{random.randint(0,10000)}'\n",
    "operation = genai.create_tuned_model(\n",
    "    # You can use a tuned model here too. Set `source_model=\"tunedModels/...\"`\n",
    "    source_model=base_model.name,\n",
    "    training_data=training_data,\n",
    "    id = name,\n",
    "    epoch_count = 4,\n",
    "    batch_size=4,\n",
    "    learning_rate=0.001,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-As7ayWDK1w8"
   },
   "source": [
    "Your tuned model is immediately added to the list of tuned models, but its status is set to \"creating\" while the model is tuned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "executionInfo": {
     "elapsed": 3117,
     "status": "ok",
     "timestamp": 1737895756495,
     "user": {
      "displayName": "Hamza Hashim",
      "userId": "13752771049705334670"
     },
     "user_tz": -300
    },
    "id": "su64KgY4Uztj",
    "outputId": "08eddd90-d0dc-48e5-a1d8-991204f85ccb"
   },
   "outputs": [],
   "source": [
    "model = genai.get_tuned_model(f'tunedModels/{name}')\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 523,
     "status": "ok",
     "timestamp": 1737895758247,
     "user": {
      "displayName": "Hamza Hashim",
      "userId": "13752771049705334670"
     },
     "user_tz": -300
    },
    "id": "EUodUwZkKPi-",
    "outputId": "c1576ed4-c3a2-49e0-c446-6922291db0b7"
   },
   "outputs": [],
   "source": [
    "model.state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pi8X5vkQv-3_"
   },
   "source": [
    "### Check tuning progress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tWI-vAh4LJIz"
   },
   "source": [
    "Use `metadata` to check the state:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 406,
     "status": "ok",
     "timestamp": 1737895763904,
     "user": {
      "displayName": "Hamza Hashim",
      "userId": "13752771049705334670"
     },
     "user_tz": -300
    },
    "id": "g08vqtxYLMxT",
    "outputId": "fb8fea66-95b7-4b2e-ad25-2855aeb0dc56"
   },
   "outputs": [],
   "source": [
    "operation.metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3lQ6gSMgK-kz"
   },
   "source": [
    "Wait for the training to finish using `operation.result()`, or `operation.wait_bar()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "18fff6aab39c49ee98d76454fcd39d75",
      "6b052b1932fc449f9aec7b3f75a774e1",
      "1670acbf53644ba4b8e19da6c5c07a31",
      "86149888fded4254904ca86659a467d0",
      "c46de6056f0e4c3b80c9d29396155910",
      "5ecf2c74229d4107aa85a45d0f21e818",
      "2239c517b9c447fa92ea382685f42b34",
      "9778dd8fd5c446eea869bab7e026c0dd",
      "b9c73885b60a4d53b28868f7db010acd",
      "a6db192e23c34db7b7b1ee691685e551",
      "8a3047be6233409b9e0562b0f8be280f"
     ]
    },
    "executionInfo": {
     "elapsed": 35864,
     "status": "ok",
     "timestamp": 1737895803754,
     "user": {
      "displayName": "Hamza Hashim",
      "userId": "13752771049705334670"
     },
     "user_tz": -300
    },
    "id": "SOUowIv1HgSE",
    "outputId": "d05e1632-3986-4cf4-dd56-948dadc6214d"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "for status in operation.wait_bar():\n",
    "  time.sleep(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4cg868HzqOx5"
   },
   "source": [
    "You can cancel your tuning job any time using the `cancel()` method. Uncomment the line below and run the code cell to cancel your job before it finishes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oQuJ70_hqJi9"
   },
   "outputs": [],
   "source": [
    "# operation.cancel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lqiL0TWDqAPn"
   },
   "source": [
    "Once the tuning is complete, you can view the loss curve from the tuning results. The [loss curve](https://ai.google.dev/gemini-api/docs/model-tuning#recommended_configurations) shows how much the model's predictions deviate from the ideal outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 466
    },
    "executionInfo": {
     "elapsed": 5053,
     "status": "ok",
     "timestamp": 1737895816203,
     "user": {
      "displayName": "Hamza Hashim",
      "userId": "13752771049705334670"
     },
     "user_tz": -300
    },
    "id": "bIiG57xWLhP7",
    "outputId": "5592a434-9283-464c-d557-b5ad49e6e966"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "model = operation.result()\n",
    "\n",
    "snapshots = pd.DataFrame(model.tuning_task.snapshots)\n",
    "\n",
    "sns.lineplot(data=snapshots, x = 'epoch', y='mean_loss')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rkoQTXb1vSBC"
   },
   "source": [
    "## Evaluate your model\n",
    "\n",
    "You can use the `genai.generate_content` method and specify the name of your model to test your model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zO0YcuSyxydZ"
   },
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel(model_name=f'tunedModels/{name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 4087,
     "status": "ok",
     "timestamp": 1737895835047,
     "user": {
      "displayName": "Hamza Hashim",
      "userId": "13752771049705334670"
     },
     "user_tz": -300
    },
    "id": "UwGrrj6hS_x2",
    "outputId": "bb61f231-3ee4-40be-ea27-9e77afc44aff"
   },
   "outputs": [],
   "source": [
    "result = model.generate_content('55')\n",
    "result.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 3711,
     "status": "ok",
     "timestamp": 1737895840082,
     "user": {
      "displayName": "Hamza Hashim",
      "userId": "13752771049705334670"
     },
     "user_tz": -300
    },
    "id": "YSNB2zjTx5SZ",
    "outputId": "2e206196-981e-46bf-9720-07b4f13f679f"
   },
   "outputs": [],
   "source": [
    "result = model.generate_content('123455')\n",
    "result.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 2593,
     "status": "ok",
     "timestamp": 1737895844539,
     "user": {
      "displayName": "Hamza Hashim",
      "userId": "13752771049705334670"
     },
     "user_tz": -300
    },
    "id": "Y2YVO-m0Ut9H",
    "outputId": "9c891cb2-d06c-467d-e540-ea34b29422f3"
   },
   "outputs": [],
   "source": [
    "result = model.generate_content('four')\n",
    "result.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 2339,
     "status": "ok",
     "timestamp": 1737895848585,
     "user": {
      "displayName": "Hamza Hashim",
      "userId": "13752771049705334670"
     },
     "user_tz": -300
    },
    "id": "h2MkTR0uTb6U",
    "outputId": "622df4f8-dca0-4980-c973-28e6e1951374"
   },
   "outputs": [],
   "source": [
    "result = model.generate_content('quatre') # French 4\n",
    "result.text                               # French 5 is \"cinq\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 2253,
     "status": "ok",
     "timestamp": 1737895882099,
     "user": {
      "displayName": "Hamza Hashim",
      "userId": "13752771049705334670"
     },
     "user_tz": -300
    },
    "id": "OruCW1zETsZw",
    "outputId": "a4c3e9fd-365a-4e0a-cfad-c279796f272d"
   },
   "outputs": [],
   "source": [
    "result = model.generate_content('III')    # Roman numeral 3\n",
    "result.text                               # Roman numeral 4 is IV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 3534,
     "status": "ok",
     "timestamp": 1737895871780,
     "user": {
      "displayName": "Hamza Hashim",
      "userId": "13752771049705334670"
     },
     "user_tz": -300
    },
    "id": "thDdSuUDUJOx",
    "outputId": "a4282103-935e-4238-ff38-41f98e1dc5c7"
   },
   "outputs": [],
   "source": [
    "result = model.generate_content('七')  # Japanese 7\n",
    "result.text                            # Japanese 8 is 八!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HpIA1IFevQQR"
   },
   "source": [
    "It really seems to have picked up the task despite the limited examples, but \"next\" is a simple concept, see the [tuning guide](https://ai.google.dev/gemini-api/docs/model-tuning) for more guidance on improving performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nmuQCbTYwIOx"
   },
   "source": [
    "## Update the description\n",
    "\n",
    "You can update the description of your tuned model any time using the `genai.update_tuned_model` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9gAVuXT_wG3x"
   },
   "outputs": [],
   "source": [
    "genai.update_tuned_model(f'tunedModels/{name}', {\"description\":\"This is my model.\"});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 2740,
     "status": "ok",
     "timestamp": 1737836376781,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -300
    },
    "id": "d-c3YerBxVYs",
    "outputId": "0858f962-3ec0-4996-da93-cecec08127dc"
   },
   "outputs": [],
   "source": [
    "model = genai.get_tuned_model(f'tunedModels/{name}')\n",
    "\n",
    "model.description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i_TpwvBB4bQ7"
   },
   "source": [
    "## Delete the model\n",
    "\n",
    "You can clean up your tuned model list by deleting models you no longer need. Use the `genai.delete_tuned_model` method to delete a model. If you canceled any tuning jobs, you may want to delete those as their performance may be unpredictable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cepfaUCvVGCo"
   },
   "outputs": [],
   "source": [
    "genai.delete_tuned_model(f'tunedModels/{name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ljEssIshYDEr"
   },
   "source": [
    "The model no longer exists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kN_bkut_4ayL",
    "outputId": "d8722d3c-241e-41ce-cbc5-9d8363634144"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "  m = genai.get_tuned_model(f'tunedModels/{name}')\n",
    "  print(m)\n",
    "except Exception as e:\n",
    "  print(f\"{type(e)}: {e}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNY7Tt5r2Efqb4BfIIx2iJf",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
